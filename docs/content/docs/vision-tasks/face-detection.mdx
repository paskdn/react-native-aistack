---
title: Face Detection (Cross-platform)
description: Detect faces in images.
---

import { Tab, Tabs } from 'fumadocs-ui/components/tabs';
import { Step, Steps } from 'fumadocs-ui/components/steps';
import { File, Folder } from 'fumadocs-ui/components/files';

The `useFaceDetector` hook lets you detect faces in images. You can use this hook to locate faces and facial features within static images.

## Usage

Here is a basic example of how to use the `useFaceDetector` hook:

```tsx
import { useFaceDetector, type FaceDetectionResult } from 'react-native-aistack';
import { View, Button, Text } from 'react-native';

const MyComponent = () => {
  const { detect, isLoading, error } = useFaceDetector(
    { uri: 'https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite' },
    { minDetectionConfidence: 0.5 }
  );

  const handleDetect = async () => {
    try {
      const result:FaceDetectionResult = await detect({ uri: 'https://your-image-url.com/image.jpg' });
      console.log('Detection result:', result);
    } catch (e) {
      console.error('Detection failed:', e);
    }
  };

  return (
    <View>
      <Button
        title="Detect Faces"
        onPress={handleDetect}
        disabled={isLoading}
      />
      {isLoading && <Text>Loading model...</Text>}
      {error && <Text>Error: {error.message}</Text>}
    </View>
  );
};
```

## Model

The `useFaceDetector` hook requires a trained face detection model in TFLite format.

### Model Source

You can provide the model using one of the following sources:

- **URI:** The model is hosted on a remote server.
- **File Path:** The model is stored on the device's file system.
- **Bundle:** The model is included in your app's assets.

```ts
// From a remote URL
const modelSource = { uri: 'https://example.com/model.tflite' };

// From a local file path
const modelSource = { filePath: '/path/to/your/model.tflite' };

// From the app bundle
const modelSource = { bundle: 'blaze_face_short_range.tflite' };
```

For more information on available models, see the [MediaPipe Face Detector models documentation](https://ai.google.dev/edge/mediapipe/solutions/vision/face_detector/index#models).

## Configuration

You can configure the face detector with the following options:

### `FaceDetectorOptions`

| Option                    | Description                                                                                   | Type     | Default |
| ------------------------- | --------------------------------------------------------------------------------------------- | -------- | ------- |
| `runningMode`             | The running mode for the task. Only `IMAGE` mode is supported.                                | `string` | `IMAGE` |
| `minDetectionConfidence`  | The minimum confidence score for the face detection to be considered successful.              | `number` | `0.5`   |
| `minSuppressionThreshold` | The minimum non-maximum-suppression threshold for face detection to be considered overlapped. | `number` | `0.3`   |

### `ImagePreprocessingOptions`

| Option      | Description                                | Type     | Default |
| ----------- | ------------------------------------------ | -------- | ------- |
| `rotation`  | The rotation to apply to the image in degrees. | `number` | `0`     |

## Result

The `detect` function returns a `FaceDetectionResult` object with the following properties:

### `FaceDetectionResult`

| Property      | Description                                                              | Type          |
| ------------- | ------------------------------------------------------------------------ | ------------- |
| `detections`  | A list of detections, sorted by score in descending order.               | `Detection[]` |
| `timestampMs` | The timestamp in milliseconds of the start of the image being processed. | `number`      |

### `Detection`

| Property      | Description                                 | Type                   |
| ------------- | ------------------------------------------- | ---------------------- |
| `categories`  | A list of categories for the detected face. | `Category[]`           |
| `boundingBox` | The bounding box of the detected face.      | `BoundingBox`          |
| `keypoints`   | Normalized keypoints for the detected face. | `NormalizedKeypoint[]` |
