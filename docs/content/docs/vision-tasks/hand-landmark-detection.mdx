---
title: Hand Landmark Detection (Android Only)
description: Detect the landmarks of the hands in an image.
---

import { Tab, Tabs } from 'fumadocs-ui/components/tabs';
import { Step, Steps } from 'fumadocs-ui/components/steps';
import { File, Folder } from 'fumadocs-ui/components/files';

The `useHandLandmarker` hook lets you detect the landmarks of the hands in an image. You can use this hook to locate key points of hands and render visual effects on them.

## Usage

Here is a basic example of how to use the `useHandLandmarker` hook:

```tsx
import { useHandLandmarker, type HandLandmarkerResult } from 'react-native-aistack';
import { View, Button, Text } from 'react-native';

const MyComponent = () => {
  const { detect, isLoading, error } = useHandLandmarker(
    { uri: 'https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/latest/hand_landmarker.task' },
    { numHands: 2 }
  );

  const handleDetect = async () => {
    try {
      const result:HandLandmarkerResult = await detect({ uri: 'https://your-image-url.com/image.jpg' });
      console.log('Detection result:', result);
    } catch (e) {
      console.error('Detection failed:', e);
    }
  };

  return (
    <View>
      <Button
        title="Detect Hand Landmarks"
        onPress={handleDetect}
        disabled={isLoading}
      />
      {isLoading && <Text>Loading model...</Text>}
      {error && <Text>Error: {error.message}</Text>}
    </View>
  );
};
```

## Model

The `useHandLandmarker` hook requires a trained hand landmarker model in TFLite format.

### Model Source

You can provide the model using one of the following sources:

- **URI:** The model is hosted on a remote server.
- **File Path:** The model is stored on the device's file system.
- **Bundle:** The model is included in your app's assets.

```ts
// From a remote URL
const modelSource = { uri: 'https://example.com/model.task' };

// From a local file path
const modelSource = { filePath: '/path/to/your/model.task' };

// From the app bundle
const modelSource = { bundle: 'hand_landmarker.task' };
```

For more information on available models, see the [MediaPipe Hand Landmarker models documentation](https://ai.google.dev/edge/mediapipe/solutions/vision/hand_landmarker/index#models).

## Configuration

You can configure the hand landmarker with the following options:

### `HandLandmarkerOptions`

| Option                       | Description                                                                                    | Type     | Default |
| ---------------------------- | ---------------------------------------------------------------------------------------------- | -------- | ------- |
| `runningMode`                | The running mode for the task. Only `IMAGE` mode is supported.                                 | `string` | `IMAGE` |
| `delegate`                   | The hardware acceleration delegate. CPU is more compatible, GPU can be faster.                 | `string` | `CPU`   |
| `numHands`                   | The maximum number of hands detected by the Hand landmark detector.                            | `number` | `1`     |
| `minHandDetectionConfidence` | The minimum confidence score for the hand detection to be considered successful.               | `number` | `0.5`   |
| `minHandPresenceConfidence`  | The minimum confidence score for the hand presence score in the hand landmark detection model. | `number` | `0.5`   |
| `minTrackingConfidence`      | The minimum confidence score for the hand tracking to be considered successful.                | `number` | `0.5`   |

### `ImagePreprocessingOptions`

| Option      | Description                                | Type     | Default |
| ----------- | ------------------------------------------ | -------- | ------- |
| `rotation`  | The rotation to apply to the image in degrees. | `number` | `0`     |

## Result

The `detect` function returns a `HandLandmarkerResult` object with the following properties:

### `HandLandmarkerResult`

| Property         | Description                                           | Type                       |
| ---------------- | ----------------------------------------------------- | -------------------------- |
| `handedness`     | Handedness of detected hands.                         | `Category[][]`             |
| `landmarks`      | Hand landmarks in image coordinates.                  | `NormalizedLandmark[][][]` |
| `worldLandmarks` | Hand landmarks in world coordinates.                  | `Landmark[][][]` |
| `timestampMs`    | The timestamp in milliseconds of the image processed. | `number`                   |